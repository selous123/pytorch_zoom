{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "class _Residual_Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_Residual_Block, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.in1 = nn.InstanceNorm2d(64, affine=True)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.in2 = nn.InstanceNorm2d(64, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity_data = x\n",
    "        output = self.relu(self.in1(self.conv1(x)))\n",
    "        output = self.in2(self.conv2(output))\n",
    "        output = torch.add(output,identity_data)\n",
    "        return output \n",
    "\n",
    "class _NetG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_NetG, self).__init__()\n",
    "\n",
    "        self.conv_input = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, stride=1, padding=4, bias=False)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "        self.residual = self.make_layer(_Residual_Block, 16)\n",
    "\n",
    "        self.conv_mid = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn_mid = nn.InstanceNorm2d(64, affine=True)\n",
    "\n",
    "        self.upscale4x = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv_output = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=9, stride=1, padding=4, bias=False)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def make_layer(self, block, num_of_layer):\n",
    "        layers = []\n",
    "        for _ in range(num_of_layer):\n",
    "            layers.append(block())\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        out = self.relu(self.conv_input(x))\n",
    "        residual = out\n",
    "        out = self.residual(out)\n",
    "        out = self.bn_mid(self.conv_mid(out))\n",
    "        out = torch.add(out,residual)\n",
    "        out = self.upscale4x(out)\n",
    "        out = self.conv_output(out)\n",
    "        return out\n",
    "    \n",
    "model = _NetG()\n",
    "model = model.cuda()\n",
    "\n",
    "x = torch.zeros([1,3,256,256]).cuda()\n",
    "output = model(x)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class _Residual_Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_Residual_Block, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.in1 = nn.InstanceNorm2d(64, affine=True)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.in2 = nn.InstanceNorm2d(64, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity_data = x\n",
    "        output = self.relu(self.in1(self.conv1(x)))\n",
    "        output = self.in2(self.conv2(output))\n",
    "        output = torch.add(output,identity_data)\n",
    "        return output \n",
    "\n",
    "class myUpsample(nn.Module):\n",
    "    def __init__(self, scale_factor, mode='bilinear', align_corners=False):\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "        self.align_corners = align_corners\n",
    "    def forward(self, input):\n",
    "        return F.interpolate(input, scale_factor=self.scale_factor, mode=self.mode, align_corners=self.align_corners)\n",
    "\n",
    "class NetARW(nn.Module):\n",
    "    def __init__(self, up_ratio=2, up_type='subpixel'):\n",
    "        super(NetARW, self).__init__()\n",
    "        \n",
    "        self.up_ratio = up_ratio\n",
    "        self.conv_input = nn.Conv2d(in_channels=4, out_channels=64, kernel_size=9, stride=1, padding=4, bias=False)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "        self.residual = self.make_layer(_Residual_Block, 16)\n",
    "\n",
    "        self.conv_mid = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn_mid = nn.InstanceNorm2d(64, affine=True)\n",
    "        if up_type == 'subpixel':\n",
    "            self.upscale2x = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.PixelShuffle(2),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.PixelShuffle(2),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "            self.upscale2x_1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.PixelShuffle(2),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "            self.upscale2x_2 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.PixelShuffle(2),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "        if up_type == 'deconv':\n",
    "            self.upscale2x = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                #F.interpolate(g_, scale_factor=self.up_factor, mode='bilinear', align_corners=False)\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "            self.upscale2x_1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "            self.upscale2x_2 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.ConvTranspose2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "        \n",
    "        self.conv_output = nn.Conv2d(in_channels=256, out_channels=3, kernel_size=9, stride=1, padding=4, bias=False)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def make_layer(self, block, num_of_layer):\n",
    "        layers = []\n",
    "        for _ in range(num_of_layer):\n",
    "            layers.append(block())\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        out = self.relu(self.conv_input(x))\n",
    "        residual = out\n",
    "        out = self.residual(out)\n",
    "        out = self.bn_mid(self.conv_mid(out))\n",
    "        out = torch.add(out,residual)\n",
    "        out = self.upscale2x(out)\n",
    "        if self.up_ratio == 4:\n",
    "            out = self.upscale2x_1(out)\n",
    "        \n",
    "        if self.up_ratio == 8:\n",
    "            out = self.upscale2x_1(out)\n",
    "            out = self.upscale2x_2(out)\n",
    "        \n",
    "        print(out.shape)\n",
    "        out = self.conv_output(out)\n",
    "        return out\n",
    "\n",
    "model = NetARW(up_type=\"deconv\", up_ratio=2)\n",
    "model = model.cuda()\n",
    "x = torch.zeros([1,4,64,64]).cuda()\n",
    "output = model(x)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a = torch.randn(1, 3, 256, 256)\n",
    "#a = torch.from_numpy(np.arange(0,256)).view(1,1,16,16)\n",
    "#print(a)\n",
    "print(a.shape)\n",
    "kernel_size = 8\n",
    "kernel_stride = 8\n",
    "a = a.unfold(2, kernel_size, kernel_stride)\n",
    "print(a.shape)\n",
    "\n",
    "a = a.unfold(3, kernel_size, kernel_stride)\n",
    "print(a.shape)\n",
    "a = a.contiguous().view(a.size(0), a.size(1), -1, a.size(4), a.size(5))\n",
    "print(a.shape)\n",
    "# #print(a)\n",
    "\n",
    "# a.permute((0,2,3,4,1)).shape\n",
    "a = a.view(a.shape[:5])\n",
    "print(a.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class PatchNonlocalPool(nn.Module):\n",
    "\n",
    "    def __init__(self, n_feats, patch_size):\n",
    "        super(PatchNonlocalPool,self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        #self.conv = nn.Conv2d(1024, 1024,kernel_size=patch_size,stride=1,padding=0,bias=False)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        #self.avg_pool2 = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b,n,h,w = x.shape\n",
    "        kernel_size = self.patch_size\n",
    "        kernel_stride = self.patch_size\n",
    "        # [b, 64, 32, 32, 8, 8]\n",
    "        # x [b, 64, 256, 256] => [b, 64, 8, 8, 1024]\n",
    "        x = x.view(x.shape[0]*x.shape[1], x.shape[2],x.shape[3])\n",
    "        a = x.unfold(1, kernel_size, kernel_stride).unfold(2,kernel_size,kernel_stride)\n",
    "        a = a.contiguous().view(a.size(0), -1, a.size(3), a.size(4))\n",
    "        # => [b*64, 1024, 8, 8]\n",
    "        #[b*64,1024,64] a_i\n",
    "        a1 = a.view(*a.shape[:2],-1)\n",
    "        #[b*64,64,1024] a_j\n",
    "        a2 = a1.permute((0,2,1))\n",
    "        #[b*64,1024,1024] => f(x_i, x_j)\n",
    "        f1 = torch.bmm(a1, a2)\n",
    "        #print(f1.shape)\n",
    "        #[b*64,1024,1,1]\n",
    "        #print(a.shape)\n",
    "        #[b*64,1024,1,1]\n",
    "        y1 = self.avg_pool(a)\n",
    "        #[b*64,1024,1]\n",
    "        y1 = y1.view(y1.shape[:3])\n",
    "        \n",
    "        #[b*64,1024,1024]\n",
    "        y2 = torch.mul(f1,y1)\n",
    "        \n",
    "        y3 = self.avg_pool(y2)\n",
    "        return y3.view(b,n,1,1)\n",
    "\n",
    "PNLpool = PatchNonlocalPool(64,16)\n",
    "PNLpool = PNLpool\n",
    "#.cuda()\n",
    "x = torch.randn(16,64,256,256)\n",
    "#.cuda()\n",
    "x = PNLpool(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(3,4,10)\n",
    "b = torch.randn(3,10,4)\n",
    "\n",
    "torch.matmul(a,b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h = w = 256\n",
    "n = 20\n",
    "\n",
    "print(h % n != 0)\n",
    "if h % n != 0:\n",
    "    print(\"hello world\")\n",
    "if h % n != 0 or w % n != 0 :\n",
    "    raise ValueError(\"n: %d can not be division by h: %d or w: %d\" %(n, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_root = '/store/dataset/SR/train_data/SRRAW/X4/train/'\n",
    "file_name = '00579_00007.png'\n",
    "diff_path = os.path.join(data_root, 'Diff', file_name)\n",
    "hr_path = os.path.join(data_root, 'HR', file_name)\n",
    "\n",
    "from PIL import Image\n",
    "diff_img_o = Image.open(diff_path)\n",
    "hr_img = Image.open(hr_path)\n",
    "\n",
    "new_height = new_width = 512\n",
    "width, height = diff_img_o.size   # Get dimensions\n",
    "\n",
    "left = (width - new_width)/2\n",
    "top = (height - new_height)/2\n",
    "right = (width + new_width)/2\n",
    "bottom = (height + new_height)/2\n",
    "\n",
    "diff_img_o = diff_img_o.crop((left, top, right, bottom))\n",
    "hr_img = hr_img.crop((left, top, right, bottom))\n",
    "#diff_img = diff_img_o.convert(\"L\")\n",
    "diff_img = diff_img_o\n",
    "import numpy as np\n",
    "\n",
    "diff_img_np = np.array(diff_img)\n",
    "hr_img_np = np.array(hr_img)\n",
    "\n",
    "diff_img_np = (diff_img_np > 50).astype(np.float32)\n",
    "\n",
    "#diff_img_np = diff_img_np[...,np.newaxis]\n",
    "#diff_img_np = np.broadcast_to(diff_img_np,(new_height,new_width,3))\n",
    "\n",
    "print(diff_img_np.shape)\n",
    "print(hr_img_np.shape)\n",
    "hr_img_np = np.multiply(hr_img_np, diff_img_np).astype(np.uint8)\n",
    "#print(hr_img_np)\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(16,16))\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(diff_img_np, cmap='gray')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(hr_img_np)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(diff_img_o)\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.imshow(diff_img_o)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0115,  0.7080,  0.4029],\n",
      "        [ 1.1801, -0.2080,  0.9660],\n",
      "        [-0.3408, -0.1401,  0.7713],\n",
      "        [-0.7147,  0.8593, -0.0528]])\n",
      "torch.Size([4, 3])\n",
      "tensor([[0.0935, 0.5219, 0.3846],\n",
      "        [0.4862, 0.1213, 0.3925],\n",
      "        [0.1900, 0.2322, 0.5778],\n",
      "        [0.1288, 0.6216, 0.2497]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(4,3)\n",
    "\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "b = F.softmax(a, dim=-1)\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.4453e+00,  7.6660e-01, -1.6690e+00,  ..., -3.2500e-01,\n",
      "           -3.1606e-01, -1.6864e+00],\n",
      "          [-1.8694e-01,  1.3925e+00, -1.1483e+00,  ...,  8.2272e-02,\n",
      "           -1.3943e+00, -2.9364e-01],\n",
      "          [-7.7659e-02,  1.1806e+00,  4.3352e-01,  ..., -9.9556e-01,\n",
      "            2.9232e-01,  1.5797e+00],\n",
      "          ...,\n",
      "          [-3.5963e-01,  9.1163e-01,  7.9232e-01,  ...,  2.4011e-01,\n",
      "           -4.4147e-01,  2.5068e-01],\n",
      "          [-3.0067e-01,  2.0332e+00,  1.5137e+00,  ..., -9.6034e-01,\n",
      "           -5.8280e-01,  3.5312e-01],\n",
      "          [-9.4486e-01, -1.9564e+00,  1.1405e+00,  ...,  2.1508e-02,\n",
      "            3.8641e-01,  1.3860e+00]],\n",
      "\n",
      "         [[ 2.9581e-01, -3.4922e-01,  1.5355e+00,  ...,  3.1994e-01,\n",
      "            9.6983e-01,  1.1500e+00],\n",
      "          [-5.6420e-01, -2.2248e+00,  3.0385e-02,  ..., -2.5731e+00,\n",
      "           -3.3326e+00, -5.3650e-01],\n",
      "          [-1.0598e+00,  8.1447e-01, -1.3055e+00,  ...,  9.4776e-02,\n",
      "           -5.0595e-01,  5.4212e-01],\n",
      "          ...,\n",
      "          [-3.0724e-01,  1.7567e+00, -6.4945e-01,  ...,  1.1745e+00,\n",
      "            2.5510e-01,  6.0857e-02],\n",
      "          [-8.5133e-02,  1.6076e+00, -2.6192e-02,  ..., -1.1005e-02,\n",
      "           -1.2907e+00,  4.1040e-01],\n",
      "          [-1.8346e+00,  1.0014e+00, -5.8355e-01,  ...,  8.0951e-01,\n",
      "            3.8445e-01, -1.2897e+00]],\n",
      "\n",
      "         [[ 2.1937e+00,  4.9627e-02, -3.2634e-01,  ..., -8.5611e-01,\n",
      "           -3.8674e-01, -4.8704e-01],\n",
      "          [ 3.3932e-01, -2.3645e-01, -8.0344e-01,  ...,  7.9098e-01,\n",
      "            9.0394e-01,  1.5898e+00],\n",
      "          [ 1.4765e+00,  1.5535e+00, -3.8574e-02,  ..., -2.2571e-01,\n",
      "           -7.6949e-01,  4.8094e-02],\n",
      "          ...,\n",
      "          [-2.7548e-01, -1.8143e+00,  7.9488e-01,  ...,  1.6100e-01,\n",
      "            1.7616e+00,  4.4179e-01],\n",
      "          [-1.5450e+00,  2.0544e+00,  1.1927e-01,  ..., -8.8553e-01,\n",
      "            1.2606e+00,  5.2378e-01],\n",
      "          [-9.9539e-01, -2.5292e+00, -1.8670e-01,  ..., -5.8422e-01,\n",
      "            3.4145e-01,  5.3188e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.9072e-01, -1.5282e+00, -5.1704e-03,  ...,  5.6425e-01,\n",
      "           -3.9711e-01, -2.9432e-01],\n",
      "          [ 2.1761e-03,  1.0808e+00,  2.4579e-01,  ..., -1.5796e+00,\n",
      "            6.0706e-01, -4.4872e-01],\n",
      "          [ 1.0680e-01, -5.7453e-02, -1.5099e+00,  ..., -5.7653e-01,\n",
      "            1.0319e+00,  1.2320e+00],\n",
      "          ...,\n",
      "          [ 2.1264e-01,  7.4083e-01, -1.0838e+00,  ...,  1.9279e+00,\n",
      "            2.0882e-01,  8.7798e-01],\n",
      "          [ 7.4661e-01, -1.5033e+00,  4.3925e-01,  ...,  4.3311e-01,\n",
      "            7.3018e-01, -1.4357e-01],\n",
      "          [ 2.5151e+00, -7.0837e-01,  1.1716e+00,  ..., -8.2065e-01,\n",
      "           -2.5645e-01,  1.8629e-01]],\n",
      "\n",
      "         [[-6.9929e-01, -2.4025e+00, -2.1330e-01,  ..., -6.9542e-01,\n",
      "           -2.0497e+00, -2.0499e-01],\n",
      "          [-1.5725e+00,  6.7188e-01,  9.0329e-01,  ..., -1.6797e+00,\n",
      "            6.4589e-01, -1.1726e+00],\n",
      "          [ 4.7903e-01,  4.1290e-01, -1.1149e+00,  ...,  7.7588e-01,\n",
      "           -7.8983e-01, -1.3874e+00],\n",
      "          ...,\n",
      "          [ 6.4073e-01,  2.2145e-01, -1.2174e-01,  ..., -8.0597e-02,\n",
      "           -9.2978e-01, -7.3864e-01],\n",
      "          [ 3.2282e-01,  8.8045e-01, -4.0906e-01,  ..., -4.3995e-01,\n",
      "            9.7934e-01, -4.5018e-01],\n",
      "          [ 8.0257e-01, -2.8605e-01, -1.0878e+00,  ..., -8.9114e-01,\n",
      "           -8.1809e-02, -9.0330e-01]],\n",
      "\n",
      "         [[-7.0036e-02, -1.8138e+00, -1.0401e+00,  ..., -2.6471e-01,\n",
      "           -7.5977e-01, -6.2580e-01],\n",
      "          [ 3.0229e-01, -1.5141e+00, -1.3168e+00,  ..., -7.2794e-01,\n",
      "            1.6098e-01, -4.9234e-01],\n",
      "          [ 3.4135e-01, -8.2930e-01,  4.0316e-01,  ..., -2.2746e-01,\n",
      "           -9.4521e-01, -7.4220e-02],\n",
      "          ...,\n",
      "          [ 4.8974e-01, -8.2948e-01, -8.2486e-01,  ..., -9.4990e-01,\n",
      "            3.8471e-01, -2.0021e-01],\n",
      "          [-6.0782e-02,  4.5251e-01, -1.0749e+00,  ..., -1.2799e+00,\n",
      "           -1.1192e+00,  6.1809e-01],\n",
      "          [-2.6779e+00, -1.6366e+00, -1.5740e+00,  ..., -2.1696e+00,\n",
      "            1.6711e-01, -1.3277e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2065e+00, -2.2387e-01,  1.7235e-01,  ..., -9.4450e-01,\n",
      "            9.7670e-01, -5.0568e-01],\n",
      "          [-1.1030e-01,  2.7892e-01, -2.7337e+00,  ...,  7.5758e-01,\n",
      "            2.6738e-01, -8.5375e-01],\n",
      "          [ 1.0796e+00,  5.6981e-01,  9.7035e-01,  ..., -1.0914e+00,\n",
      "            6.3098e-01,  9.8153e-01],\n",
      "          ...,\n",
      "          [ 1.1642e+00,  6.1505e-01,  6.9958e-01,  ..., -1.2870e+00,\n",
      "            1.4257e+00,  1.0841e-01],\n",
      "          [ 6.5900e-01, -9.5576e-01, -2.6999e-01,  ...,  1.2321e+00,\n",
      "           -3.6284e-01,  1.3917e+00],\n",
      "          [ 8.1296e-01, -1.0856e+00,  2.6742e-01,  ..., -8.3126e-01,\n",
      "            1.7121e-02,  2.2387e-01]],\n",
      "\n",
      "         [[ 9.6940e-01,  5.2568e-01, -1.4995e+00,  ...,  8.5772e-01,\n",
      "           -9.5706e-01,  2.0669e-01],\n",
      "          [-1.7492e-01,  3.3965e-01, -6.2982e-01,  ..., -6.6451e-01,\n",
      "           -3.5414e-01,  1.2988e-01],\n",
      "          [-3.4297e-01, -9.9602e-01,  1.8962e-01,  ...,  2.2596e-01,\n",
      "            1.2802e+00,  8.8651e-01],\n",
      "          ...,\n",
      "          [ 5.9533e-01, -1.0650e-01,  2.6159e-01,  ...,  4.6579e-01,\n",
      "            1.7938e+00,  3.0603e-01],\n",
      "          [-1.2882e+00,  1.1534e+00, -1.5342e+00,  ...,  5.9723e-01,\n",
      "           -9.0197e-02,  9.5583e-02],\n",
      "          [ 4.4386e-01,  1.9095e+00,  9.9958e-02,  ..., -3.3922e-01,\n",
      "            5.4801e-01,  4.6229e-01]],\n",
      "\n",
      "         [[ 1.8005e+00,  2.4507e+00,  1.7576e+00,  ..., -1.1240e+00,\n",
      "           -1.7481e+00,  2.6847e-01],\n",
      "          [ 1.1674e+00, -2.3031e-01, -1.0071e+00,  ..., -8.3426e-01,\n",
      "           -2.3121e-01,  3.7113e-01],\n",
      "          [-1.9263e+00, -3.5447e-01,  5.6438e-01,  ...,  3.3306e-01,\n",
      "           -4.9562e-02,  3.0722e-01],\n",
      "          ...,\n",
      "          [ 3.2236e-01, -3.2211e-01, -5.1672e-02,  ..., -1.1123e+00,\n",
      "            6.9051e-01, -4.3974e-01],\n",
      "          [-1.8251e+00, -4.3966e-01,  7.2249e-01,  ...,  6.1256e-02,\n",
      "            6.1613e-01, -1.4796e+00],\n",
      "          [-1.4557e+00, -3.5690e-01,  1.4350e+00,  ..., -4.0063e-01,\n",
      "           -6.6429e-01,  4.7803e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1661e+00,  1.0164e-01, -1.5148e+00,  ...,  5.8129e-01,\n",
      "           -2.8709e-01, -3.8068e-02],\n",
      "          [ 6.6800e-01, -8.0816e-01, -1.2594e+00,  ...,  1.0342e-01,\n",
      "            3.7446e-01,  1.2836e+00],\n",
      "          [-1.9801e+00, -1.6488e+00, -3.0939e-01,  ...,  1.1218e+00,\n",
      "           -5.2474e-04,  2.0792e+00],\n",
      "          ...,\n",
      "          [ 7.3807e-01, -3.6122e-01, -2.1110e+00,  ...,  1.2224e+00,\n",
      "           -1.0768e-01,  4.2348e-01],\n",
      "          [ 2.3843e+00,  1.5694e+00, -3.4670e-01,  ..., -9.9957e-01,\n",
      "           -2.2091e-01,  1.3030e+00],\n",
      "          [-1.5287e+00,  6.1457e-01,  5.6914e-01,  ..., -5.2610e-01,\n",
      "            2.6558e-01, -1.0154e+00]],\n",
      "\n",
      "         [[ 2.1441e-01, -1.4023e-02, -6.2737e-01,  ..., -4.6928e-01,\n",
      "           -1.7921e+00, -1.4542e-01],\n",
      "          [-1.4659e+00,  5.8225e-01, -2.6660e+00,  ...,  7.8779e-01,\n",
      "            2.9017e-01,  9.3535e-01],\n",
      "          [ 1.4048e+00, -6.9831e-01,  1.0808e+00,  ...,  3.5079e-01,\n",
      "           -2.1096e+00,  1.4408e-01],\n",
      "          ...,\n",
      "          [ 6.0508e-01, -1.5232e+00,  5.6758e-01,  ...,  5.7108e-02,\n",
      "           -7.2606e-01,  1.2202e+00],\n",
      "          [ 8.9382e-01,  4.6200e-01,  8.7711e-01,  ..., -6.8926e-02,\n",
      "            2.2482e-01, -1.6636e-01],\n",
      "          [ 1.1041e+00, -1.1616e+00, -1.2694e+00,  ...,  2.2915e-02,\n",
      "           -3.7949e-01,  8.8455e-01]],\n",
      "\n",
      "         [[-6.9333e-01,  3.3045e-01, -2.3598e-01,  ..., -6.5255e-01,\n",
      "           -3.8724e-01,  1.3074e-02],\n",
      "          [-3.1098e-01,  4.3159e-01, -7.9556e-02,  ...,  5.8804e-02,\n",
      "           -1.0769e+00, -8.0680e-01],\n",
      "          [ 4.5698e-01, -6.3673e-01, -1.1246e+00,  ...,  3.3528e-01,\n",
      "           -1.3584e+00, -1.0292e+00],\n",
      "          ...,\n",
      "          [ 7.2086e-01,  6.1535e-01,  1.1525e+00,  ..., -7.2964e-01,\n",
      "           -7.9358e-01,  1.7505e+00],\n",
      "          [ 4.2455e-01, -4.4581e-01, -1.6844e-01,  ...,  2.5842e-01,\n",
      "           -2.0478e+00,  8.5187e-01],\n",
      "          [-2.0320e+00, -1.1416e-01, -1.0484e+00,  ...,  5.6599e-01,\n",
      "            1.5004e+00,  1.9783e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.1572e-01, -8.6348e-02,  1.3675e+00,  ..., -6.6738e-01,\n",
      "            1.0327e+00, -1.8639e+00],\n",
      "          [ 3.0152e-01,  1.1940e+00,  7.2209e-01,  ..., -9.7260e-01,\n",
      "           -1.2031e-01,  1.5639e-01],\n",
      "          [ 1.2380e+00, -9.7833e-01,  7.9215e-01,  ...,  2.3674e+00,\n",
      "            2.2480e+00,  3.5073e-01],\n",
      "          ...,\n",
      "          [ 2.6991e-01,  3.5702e-01, -4.3410e-01,  ...,  1.8117e+00,\n",
      "            3.2443e-01, -2.4071e-01],\n",
      "          [ 8.2084e-01, -2.2937e-01,  1.1623e-01,  ...,  3.1613e-01,\n",
      "           -5.2313e-01,  3.0697e-01],\n",
      "          [-2.5478e-01, -5.0277e-01,  1.6790e+00,  ..., -7.0922e-01,\n",
      "            3.9344e-01, -7.2771e-01]],\n",
      "\n",
      "         [[ 1.6224e+00, -1.0263e+00,  6.8089e-01,  ..., -1.7475e+00,\n",
      "           -1.1691e+00,  1.3253e+00],\n",
      "          [ 9.1499e-01, -7.4412e-01,  1.1030e+00,  ..., -1.5276e+00,\n",
      "            4.8268e-02, -2.0639e+00],\n",
      "          [ 1.3667e+00,  7.0521e-01,  4.4506e-01,  ...,  2.5004e-01,\n",
      "           -3.8440e-01, -2.8503e+00],\n",
      "          ...,\n",
      "          [-1.7002e+00,  2.1381e+00, -3.8435e-01,  ..., -2.6924e-01,\n",
      "           -1.4087e+00, -1.4541e-01],\n",
      "          [ 6.3702e-02, -7.5137e-01,  1.0657e+00,  ...,  4.3160e-01,\n",
      "           -4.1031e-01, -5.8971e-01],\n",
      "          [-5.1808e-01,  1.1487e+00, -5.8530e-01,  ..., -2.9150e-01,\n",
      "            5.2091e-01,  6.6290e-01]],\n",
      "\n",
      "         [[ 2.9479e-02, -1.3098e+00,  1.0118e-01,  ...,  7.0488e-01,\n",
      "           -1.4882e+00,  1.0933e+00],\n",
      "          [ 1.5377e-01, -9.8713e-01,  6.9317e-01,  ...,  7.9118e-02,\n",
      "           -2.6745e-01, -1.2566e+00],\n",
      "          [-1.1317e+00, -6.3875e-01, -1.2449e+00,  ...,  1.7575e+00,\n",
      "           -1.1794e+00, -3.8732e-01],\n",
      "          ...,\n",
      "          [-1.2679e+00, -1.2528e+00,  4.5615e-01,  ...,  5.9544e-01,\n",
      "           -7.4064e-01,  1.3563e+00],\n",
      "          [ 4.6363e-01, -1.3662e+00,  1.5347e-01,  ...,  1.6205e+00,\n",
      "           -8.5763e-01,  5.6665e-01],\n",
      "          [-1.5909e-01, -1.1774e+00, -1.9365e+00,  ..., -1.1189e+00,\n",
      "           -1.4844e+00,  2.6747e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7065e-01,  2.3444e-01,  3.2505e-01,  ...,  1.1785e+00,\n",
      "            2.1903e-01, -2.5561e-01],\n",
      "          [-2.5824e-01, -1.2970e+00, -3.3044e-01,  ..., -5.3486e-01,\n",
      "            7.8143e-01, -2.6506e-01],\n",
      "          [-2.2776e+00, -2.1945e+00,  6.4794e-01,  ...,  1.5776e-01,\n",
      "            1.1968e+00, -6.6377e-01],\n",
      "          ...,\n",
      "          [-4.4583e-01,  1.2933e+00, -1.3310e-01,  ..., -2.3902e-01,\n",
      "           -7.0993e-01, -9.0169e-01],\n",
      "          [ 1.7092e+00,  2.0770e-01,  4.8941e-01,  ..., -2.0430e-02,\n",
      "           -2.8950e-02, -8.0972e-01],\n",
      "          [ 1.7368e-01,  1.2696e+00, -9.8772e-01,  ...,  9.8285e-01,\n",
      "           -4.8535e-01,  8.6758e-01]],\n",
      "\n",
      "         [[-3.2370e-02, -1.1373e+00, -1.0542e+00,  ...,  2.0994e-01,\n",
      "           -1.6471e+00,  8.6132e-01],\n",
      "          [-1.2725e-01, -1.3913e+00, -7.8557e-01,  ..., -1.0435e+00,\n",
      "            6.7572e-01, -4.1533e-01],\n",
      "          [-4.4578e-01,  9.2087e-01,  1.7153e+00,  ..., -2.6610e-01,\n",
      "            7.3093e-01,  3.5417e-01],\n",
      "          ...,\n",
      "          [ 3.2347e-01, -5.6358e-01, -4.1912e-01,  ..., -9.5148e-01,\n",
      "            1.5734e+00, -2.4182e-01],\n",
      "          [-2.2830e-01, -8.1430e-01,  3.1256e-01,  ..., -8.5978e-01,\n",
      "            4.9794e-01,  6.0132e-01],\n",
      "          [ 1.9604e+00,  4.1899e-01,  6.3610e-01,  ..., -8.2547e-01,\n",
      "           -2.0127e+00, -1.9746e+00]],\n",
      "\n",
      "         [[ 1.5979e+00, -1.3743e+00, -1.3812e+00,  ...,  5.4771e-01,\n",
      "           -8.1024e-01,  9.8098e-01],\n",
      "          [-6.1826e-01,  2.1857e-01,  4.8766e-02,  ...,  1.2788e+00,\n",
      "            5.0497e-01,  4.8432e-01],\n",
      "          [-1.4302e-01,  4.7414e-02,  1.2918e+00,  ...,  1.9109e+00,\n",
      "           -3.9708e-02,  5.3186e-01],\n",
      "          ...,\n",
      "          [-2.4716e-01, -1.3184e+00,  2.2706e+00,  ...,  7.7010e-01,\n",
      "           -7.2587e-01, -4.2496e-01],\n",
      "          [ 1.5412e+00, -4.4178e-01, -3.8079e-02,  ...,  3.5288e-01,\n",
      "            1.3408e+00, -1.0166e-03],\n",
      "          [ 2.3845e+00,  7.8810e-02, -7.7849e-01,  ..., -9.3087e-03,\n",
      "           -9.9160e-01,  6.2164e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-9.5694e-02,  8.2743e-01,  1.0331e+00,  ...,  5.8838e-01,\n",
      "           -1.3282e+00, -1.0177e+00],\n",
      "          [ 1.0032e-01, -2.7535e-01,  1.1758e+00,  ...,  1.1312e+00,\n",
      "            2.3642e-01, -6.1880e-01],\n",
      "          [ 2.6579e+00, -6.7670e-01,  1.5339e+00,  ..., -7.2831e-01,\n",
      "           -3.0912e-01, -6.9047e-01],\n",
      "          ...,\n",
      "          [ 9.1772e-02,  1.5967e+00,  1.3431e+00,  ..., -1.9130e+00,\n",
      "           -1.1151e+00, -1.5223e+00],\n",
      "          [-1.3103e+00, -3.0766e-01,  4.8255e-01,  ...,  1.8126e+00,\n",
      "            8.9827e-03,  7.8885e-01],\n",
      "          [-2.0909e-01,  8.9841e-03,  1.9469e+00,  ..., -1.4158e+00,\n",
      "            1.3528e-01,  1.5924e+00]],\n",
      "\n",
      "         [[-8.8923e-01, -1.3498e+00,  6.6710e-01,  ..., -7.5684e-01,\n",
      "           -2.1506e-01, -4.1488e-01],\n",
      "          [ 6.5349e-01, -1.7622e+00, -6.0573e-01,  ...,  2.3814e-02,\n",
      "           -4.4570e-01, -6.8629e-01],\n",
      "          [ 1.0569e+00, -7.4387e-01, -6.3390e-01,  ..., -1.9882e+00,\n",
      "           -3.8476e-01,  4.9816e-01],\n",
      "          ...,\n",
      "          [ 2.1253e-02, -5.0007e-01,  2.2370e-02,  ..., -5.8499e-01,\n",
      "           -3.7604e-02,  3.6405e-01],\n",
      "          [ 1.1294e-01,  3.1670e+00, -1.5478e+00,  ...,  1.1341e+00,\n",
      "            6.2071e-01, -4.4713e-01],\n",
      "          [-1.4057e+00,  4.1379e-01,  6.5171e-01,  ..., -2.1012e+00,\n",
      "           -9.0969e-01, -3.5183e-01]],\n",
      "\n",
      "         [[ 7.3722e-03, -8.2157e-01,  1.6681e-01,  ...,  3.1863e-02,\n",
      "            5.2487e-02, -5.3685e-01],\n",
      "          [ 3.9947e-02, -1.5301e+00, -1.3859e-01,  ..., -7.5539e-01,\n",
      "            4.8763e-01,  3.1652e-01],\n",
      "          [-3.8013e-01,  4.4487e-01, -3.4805e-01,  ..., -1.5414e+00,\n",
      "            5.9465e-01, -1.2381e+00],\n",
      "          ...,\n",
      "          [-1.4545e-02,  8.0382e-01, -7.3334e-01,  ..., -4.0936e-01,\n",
      "           -1.3066e+00, -4.2468e-01],\n",
      "          [ 3.9255e-01, -1.5072e-01, -1.2473e+00,  ...,  1.1676e+00,\n",
      "           -6.1359e-02, -1.6656e+00],\n",
      "          [ 5.5154e-01,  2.7308e-01, -1.0415e+00,  ..., -1.4567e+00,\n",
      "           -1.6796e+00,  7.6325e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4679e-01, -8.1896e-01, -3.1704e-01,  ...,  2.9902e+00,\n",
      "            3.2088e-01,  1.8389e-01],\n",
      "          [-1.9346e+00, -1.6976e-02,  4.3481e-01,  ...,  1.1551e-01,\n",
      "           -1.2161e+00,  5.4414e-01],\n",
      "          [-9.8139e-01,  7.9187e-01,  9.4475e-01,  ...,  3.0482e-01,\n",
      "           -2.0375e-01, -1.6984e-02],\n",
      "          ...,\n",
      "          [-1.3773e+00,  7.6244e-01,  8.1182e-02,  ...,  5.9296e-01,\n",
      "            1.2670e-01, -5.3038e-01],\n",
      "          [-1.2859e+00,  1.8821e+00, -3.9164e-01,  ...,  8.1525e-01,\n",
      "           -3.8844e-01,  1.1635e-01],\n",
      "          [-5.9010e-01, -2.1115e+00, -5.9604e-01,  ...,  2.2666e+00,\n",
      "           -3.1090e-01, -9.3895e-01]],\n",
      "\n",
      "         [[ 1.0945e+00,  8.9387e-01,  4.3622e-01,  ...,  4.0458e-01,\n",
      "            3.6793e-01, -1.3747e-01],\n",
      "          [-1.2837e-01, -1.7499e-01, -1.8429e-01,  ...,  6.5062e-01,\n",
      "           -1.2374e+00, -7.3488e-01],\n",
      "          [-5.6608e-01,  5.8646e-01, -9.8909e-01,  ...,  9.4568e-01,\n",
      "            1.0717e+00,  1.0641e+00],\n",
      "          ...,\n",
      "          [ 1.5459e+00, -6.0021e-01,  1.8383e+00,  ...,  2.3116e-01,\n",
      "            1.3420e-01,  1.1716e+00],\n",
      "          [-9.4628e-01, -7.2290e-02, -6.2454e-01,  ...,  4.2984e-01,\n",
      "           -6.1047e-02,  3.0259e-01],\n",
      "          [-4.5504e-01,  1.1700e+00,  1.2104e+00,  ..., -1.9267e-02,\n",
      "           -1.5817e+00, -6.0825e-01]],\n",
      "\n",
      "         [[ 5.8057e-01,  2.4337e+00, -9.4395e-01,  ..., -8.5557e-01,\n",
      "            9.3648e-01,  1.4648e+00],\n",
      "          [ 1.0190e-01, -5.8783e-01,  8.7168e-01,  ...,  1.7627e+00,\n",
      "            4.0803e-01,  1.5936e+00],\n",
      "          [ 1.1480e-01, -1.7356e-01, -2.5725e+00,  ..., -8.3192e-02,\n",
      "           -7.3753e-01, -2.6432e-01],\n",
      "          ...,\n",
      "          [ 2.6824e-01, -8.7397e-01, -9.8795e-01,  ..., -8.2143e-01,\n",
      "           -8.4541e-01, -4.9292e-01],\n",
      "          [-1.8122e+00,  1.2356e+00, -1.9744e-01,  ...,  9.3559e-01,\n",
      "           -5.3839e-01,  1.5062e-01],\n",
      "          [ 1.4489e+00,  9.0790e-01, -3.1859e-01,  ...,  1.3102e+00,\n",
      "            9.9281e-01,  3.3833e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1827e-01, -1.1899e-01, -7.3829e-01,  ...,  5.3781e-01,\n",
      "            1.4382e+00,  9.7370e-02],\n",
      "          [-1.7790e+00, -1.5652e+00, -9.0781e-01,  ...,  7.6840e-01,\n",
      "            2.8904e-01,  1.4106e+00],\n",
      "          [-4.9580e-01,  1.0077e+00, -4.2254e-01,  ..., -1.8414e+00,\n",
      "            1.7489e+00, -1.7936e-01],\n",
      "          ...,\n",
      "          [-4.7596e-01,  3.9010e-01,  1.9845e+00,  ..., -1.1645e+00,\n",
      "           -1.5372e-01,  2.9175e-01],\n",
      "          [ 3.5220e-01, -7.3695e-01,  4.8723e-01,  ..., -1.2835e+00,\n",
      "           -1.2646e+00,  3.0428e-01],\n",
      "          [ 2.5321e-01,  2.3939e-01,  1.1340e+00,  ...,  5.8424e-01,\n",
      "           -1.6285e+00,  1.0390e-01]],\n",
      "\n",
      "         [[-1.4920e+00, -6.7855e-03,  1.7353e+00,  ..., -8.1057e-01,\n",
      "           -7.6820e-01,  2.3002e+00],\n",
      "          [-9.9701e-01, -1.2561e-02,  6.6416e-01,  ..., -5.0762e-01,\n",
      "            4.4372e-01, -6.6412e-01],\n",
      "          [-9.7732e-01, -8.5562e-02, -3.4831e-01,  ...,  1.2019e+00,\n",
      "            4.0611e-01,  4.8955e-01],\n",
      "          ...,\n",
      "          [-6.8569e-01, -1.6199e+00,  8.7741e-01,  ..., -1.2553e+00,\n",
      "           -3.2643e-01,  3.8060e-01],\n",
      "          [-1.3684e+00, -7.4410e-02,  2.7647e-01,  ...,  1.2899e+00,\n",
      "            1.1797e+00, -1.1320e+00],\n",
      "          [ 2.1745e-01,  1.6207e+00,  1.1399e+00,  ..., -1.9033e+00,\n",
      "           -4.4941e-01,  1.1491e+00]],\n",
      "\n",
      "         [[ 6.9217e-01,  3.7121e-01,  1.1795e+00,  ..., -1.3473e+00,\n",
      "           -6.5416e-01,  1.1741e+00],\n",
      "          [-1.3147e+00, -1.6857e-01, -3.0419e-01,  ..., -1.2699e+00,\n",
      "            9.5286e-01, -1.3839e-01],\n",
      "          [ 4.6005e-01, -2.2515e-01,  1.3431e+00,  ..., -8.5791e-01,\n",
      "           -1.5242e+00, -7.0231e-01],\n",
      "          ...,\n",
      "          [ 8.1678e-01,  2.0999e-01,  2.2580e-02,  ...,  1.6916e-01,\n",
      "            1.4420e+00,  9.3797e-01],\n",
      "          [-3.1109e-02,  2.5194e-01, -5.0912e-01,  ...,  1.5548e+00,\n",
      "           -1.4819e+00,  7.5049e-01],\n",
      "          [-1.6549e+00,  1.9985e+00,  3.3334e-01,  ...,  1.6644e+00,\n",
      "           -7.1592e-02,  2.9359e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3347e+00,  1.5016e-01,  9.7806e-01,  ..., -4.9781e-01,\n",
      "           -2.3787e-01, -2.5182e-01],\n",
      "          [-2.2714e+00,  5.3640e-02,  1.6359e+00,  ..., -8.9767e-01,\n",
      "           -7.0420e-01,  1.7755e-01],\n",
      "          [-1.8932e+00,  8.1208e-01, -1.4391e+00,  ...,  1.3486e-01,\n",
      "           -7.1063e-01, -4.4531e-01],\n",
      "          ...,\n",
      "          [-7.7842e-01, -8.2886e-02, -5.1288e-01,  ..., -8.0967e-01,\n",
      "            1.2136e+00,  4.3847e-01],\n",
      "          [-1.0192e+00,  1.5194e+00,  4.4877e-01,  ..., -1.0061e+00,\n",
      "           -3.3776e-01, -9.8684e-01],\n",
      "          [ 8.1177e-01,  1.4818e+00, -6.5693e-02,  ..., -1.6733e-01,\n",
      "           -5.1841e-02,  9.1285e-01]],\n",
      "\n",
      "         [[-5.3295e-01,  1.4174e+00,  1.3501e+00,  ...,  5.7820e-01,\n",
      "            1.2815e+00, -3.3536e-02],\n",
      "          [ 6.0903e-01,  6.2343e-01, -4.0676e-01,  ...,  1.1351e+00,\n",
      "            1.0437e+00,  1.0600e+00],\n",
      "          [ 1.7588e+00,  4.5095e-01, -1.3886e+00,  ...,  1.2164e+00,\n",
      "           -8.0631e-01, -1.6067e+00],\n",
      "          ...,\n",
      "          [ 8.0343e-01,  7.0828e-01, -2.0431e+00,  ...,  2.2373e-01,\n",
      "            1.1809e+00, -9.5622e-01],\n",
      "          [-2.1595e+00,  8.8576e-01,  9.0653e-01,  ...,  2.1481e-01,\n",
      "           -5.6702e-01, -4.9543e-01],\n",
      "          [ 9.2542e-01, -1.3106e+00, -4.0646e-01,  ...,  8.2543e-02,\n",
      "            2.7615e-01,  3.6764e-01]],\n",
      "\n",
      "         [[ 2.1910e+00,  4.7115e-01, -1.2300e+00,  ..., -4.8456e-01,\n",
      "           -1.3893e+00,  7.4325e-02],\n",
      "          [ 1.7658e+00,  1.5855e+00, -6.5290e-01,  ...,  3.7273e-01,\n",
      "           -1.0076e+00, -6.0050e-01],\n",
      "          [-3.7278e-01, -1.1710e+00, -1.5403e-01,  ...,  7.8315e-01,\n",
      "            1.5789e-02,  1.9673e+00],\n",
      "          ...,\n",
      "          [-5.6707e-01,  1.5778e+00,  6.1476e-01,  ...,  1.4947e-01,\n",
      "            6.8760e-01,  2.1046e+00],\n",
      "          [ 1.2787e-01,  2.9284e+00, -3.8795e-01,  ...,  7.5848e-01,\n",
      "           -3.1148e-02,  1.4715e-01],\n",
      "          [-7.0619e-01,  1.5107e+00, -1.2676e+00,  ...,  5.2460e-01,\n",
      "            8.2798e-01, -1.1775e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7206e-01, -1.0551e+00, -3.1055e-01,  ...,  1.2953e+00,\n",
      "            6.3734e-01, -8.4604e-01],\n",
      "          [-6.5306e-01, -9.5123e-01,  7.0874e-01,  ...,  9.2652e-01,\n",
      "            3.0981e-01, -1.7309e+00],\n",
      "          [ 3.6604e-01, -5.7281e-01, -1.0727e+00,  ...,  4.1389e-01,\n",
      "           -9.5777e-01, -7.1839e-01],\n",
      "          ...,\n",
      "          [ 2.3392e-01,  6.0379e-02,  3.4325e+00,  ..., -1.8435e-01,\n",
      "           -2.0173e+00, -1.2929e+00],\n",
      "          [-2.7560e-01,  6.1947e-01,  3.9702e-01,  ..., -1.6445e+00,\n",
      "            1.2484e+00, -3.8801e-01],\n",
      "          [-8.7699e-01,  3.2465e-01, -4.2472e-02,  ...,  8.4716e-01,\n",
      "           -1.1725e+00,  2.9861e+00]],\n",
      "\n",
      "         [[-1.9153e-01, -1.0852e-01, -1.2025e+00,  ..., -9.3788e-01,\n",
      "            2.0672e+00,  3.1542e-01],\n",
      "          [ 3.1979e-01, -1.2011e-01, -1.1587e-02,  ...,  3.9689e-01,\n",
      "            4.8106e-01, -2.2534e-01],\n",
      "          [-6.9362e-01,  1.7371e+00,  1.3131e+00,  ..., -3.8247e-01,\n",
      "            7.9747e-01, -2.8162e-01],\n",
      "          ...,\n",
      "          [-2.2587e-01,  2.1740e+00, -2.1898e+00,  ...,  1.4095e-01,\n",
      "           -5.5389e-01,  1.0476e+00],\n",
      "          [-2.0938e+00,  8.2429e-01, -6.0066e-01,  ..., -1.1235e-01,\n",
      "           -2.8820e-01,  7.2673e-01],\n",
      "          [ 1.7507e-01, -1.5562e+00, -1.9464e+00,  ..., -1.4238e+00,\n",
      "            2.9929e-01,  1.2342e+00]],\n",
      "\n",
      "         [[ 6.6873e-01, -7.7048e-01,  1.9112e-01,  ..., -1.0099e+00,\n",
      "            1.7671e+00,  1.2866e+00],\n",
      "          [-2.1341e+00,  9.5342e-01, -5.6095e-01,  ...,  6.4724e-01,\n",
      "            2.5370e-01,  1.0791e+00],\n",
      "          [ 5.6480e-01,  4.8913e-01, -3.2979e-01,  ...,  7.8911e-01,\n",
      "            5.8249e-01,  2.0976e-01],\n",
      "          ...,\n",
      "          [ 1.2033e+00, -1.2453e+00,  3.1047e-01,  ..., -1.4050e+00,\n",
      "           -5.0841e-01, -6.9642e-01],\n",
      "          [-1.3052e+00,  9.9627e-01,  7.3928e-01,  ...,  2.1888e-01,\n",
      "           -1.2576e+00, -1.7244e+00],\n",
      "          [ 5.0435e-01,  1.1020e+00,  8.6978e-01,  ..., -5.2402e-02,\n",
      "            4.3054e-01, -9.4428e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2167e+00,  1.0040e+00,  5.3390e-01,  ..., -2.9069e-01,\n",
      "            1.7994e-01, -1.3589e-02],\n",
      "          [-8.8243e-02, -1.4965e+00,  1.0088e+00,  ...,  1.4710e+00,\n",
      "           -7.3032e-02, -2.3781e+00],\n",
      "          [-2.4284e+00,  1.0119e+00,  3.6931e-01,  ..., -2.7652e-01,\n",
      "            2.8602e-01, -1.3808e+00],\n",
      "          ...,\n",
      "          [-2.4454e-01, -3.5853e-02, -1.0152e+00,  ..., -2.3649e+00,\n",
      "           -5.7089e-01, -7.3536e-01],\n",
      "          [ 8.3651e-01,  7.0022e-01,  1.4767e+00,  ..., -2.3487e-02,\n",
      "            1.0437e+00, -3.6103e-01],\n",
      "          [-1.2259e+00, -6.2174e-02,  4.2881e-01,  ...,  3.1038e+00,\n",
      "            6.0117e-01, -1.1236e+00]],\n",
      "\n",
      "         [[-1.4539e+00,  1.7261e+00,  3.2068e-01,  ...,  3.4018e-01,\n",
      "            8.8280e-01,  1.1449e+00],\n",
      "          [-7.3295e-01,  6.5319e-01,  5.2052e-01,  ...,  3.8547e-01,\n",
      "           -5.4587e-01, -3.3985e-01],\n",
      "          [ 1.0321e-01, -1.5056e-01,  4.6792e-01,  ...,  6.2235e-03,\n",
      "            2.8133e-01,  8.8530e-01],\n",
      "          ...,\n",
      "          [-1.6302e+00, -3.7474e-01, -9.1687e-01,  ..., -3.6268e-02,\n",
      "            4.9274e-01,  7.1999e-01],\n",
      "          [-1.7466e+00,  7.9477e-01, -1.0019e+00,  ..., -5.6400e-01,\n",
      "           -4.6158e-01, -6.7764e-03],\n",
      "          [ 6.7710e-01,  5.3707e-01,  1.2295e+00,  ...,  4.4153e-02,\n",
      "           -3.9202e-01, -7.9157e-01]],\n",
      "\n",
      "         [[ 4.5164e-01, -7.3886e-01,  1.5533e+00,  ...,  6.1105e-02,\n",
      "            8.9736e-01, -8.7255e-01],\n",
      "          [-9.4941e-01, -1.1441e+00,  9.3175e-01,  ...,  1.5981e+00,\n",
      "           -2.0637e-01,  2.1053e+00],\n",
      "          [ 1.4992e-01, -1.8183e+00,  3.9959e-01,  ...,  7.2214e-02,\n",
      "            1.3102e-01, -6.4295e-01],\n",
      "          ...,\n",
      "          [-7.8228e-01, -1.1019e+00, -1.8004e+00,  ...,  8.5109e-02,\n",
      "           -1.7025e+00, -6.3776e-01],\n",
      "          [ 1.3467e+00, -2.1636e+00, -5.0054e-01,  ...,  2.2737e-03,\n",
      "            6.7451e-01, -1.8507e-01],\n",
      "          [ 6.2976e-01, -7.3075e-01,  8.9196e-02,  ...,  9.1870e-01,\n",
      "            9.5811e-01,  5.1162e-01]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[-3.9515e-03]],\n",
       "\n",
       "         [[-1.5727e-03]],\n",
       "\n",
       "         [[ 3.5080e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.1723e-03]],\n",
       "\n",
       "         [[ 2.6100e-03]],\n",
       "\n",
       "         [[ 1.5809e-03]]],\n",
       "\n",
       "\n",
       "        [[[-1.5049e-04]],\n",
       "\n",
       "         [[ 4.0881e-03]],\n",
       "\n",
       "         [[ 4.4255e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.4579e-04]],\n",
       "\n",
       "         [[-3.9191e-03]],\n",
       "\n",
       "         [[-1.7382e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 1.8458e-04]],\n",
       "\n",
       "         [[ 2.8802e-04]],\n",
       "\n",
       "         [[-3.6983e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.6894e-03]],\n",
       "\n",
       "         [[-6.4117e-04]],\n",
       "\n",
       "         [[ 7.8141e-04]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-7.1010e-04]],\n",
       "\n",
       "         [[-2.7668e-03]],\n",
       "\n",
       "         [[ 7.9627e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 8.5203e-04]],\n",
       "\n",
       "         [[ 5.4320e-04]],\n",
       "\n",
       "         [[ 1.5713e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 5.4359e-04]],\n",
       "\n",
       "         [[-8.3872e-06]],\n",
       "\n",
       "         [[ 8.0392e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0794e-03]],\n",
       "\n",
       "         [[ 2.4431e-03]],\n",
       "\n",
       "         [[-7.9084e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4515e-03]],\n",
       "\n",
       "         [[ 5.3454e-04]],\n",
       "\n",
       "         [[-1.6268e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.1408e-03]],\n",
       "\n",
       "         [[-1.3064e-03]],\n",
       "\n",
       "         [[ 5.1959e-04]]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class PatchNonlocalPool(nn.Module):\n",
    "    def __init__(self, n_feats, patch_size=16):\n",
    "        super(PatchNonlocalPool,self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.conv = nn.Conv2d(n_feats, n_feats,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.avg_pool1 = nn.AdaptiveAvgPool2d(1)\n",
    "        self.avg_pool2 = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b,n,h,w = x.shape\n",
    "        kernel_size = self.patch_size\n",
    "        kernel_stride = self.patch_size\n",
    "        # [b*64, 16, 16, 16, 16]\n",
    "        # x [b*64, 256, 256] => [b*64, 256, 16, 16]\n",
    "        x = x.view(b*n, h,w)\n",
    "        a = x.unfold(1, kernel_size, kernel_stride).unfold(2,kernel_size,kernel_stride)\n",
    "        a = a.contiguous().view(a.size(0), -1, a.size(3), a.size(4))\n",
    "        # => [b*64, 256, 16, 16]\n",
    "        #[b*64,256,256_fm] a_i\n",
    "        a1 = a.view(*a.shape[:2],-1)\n",
    "        #[b*64,256_fm,256] a_j\n",
    "        a2 = a1.permute((0,2,1))\n",
    "        #[b*64,256,256] => f(x_i, x_j)\n",
    "        f1 = torch.matmul(a1, a2)\n",
    "        f_div_C = F.softmax(f1, dim=-1)\n",
    "        #[b*64,256,1,1]\n",
    "        y1 = self.avg_pool1(a)\n",
    "        #[b*64,256,1]\n",
    "        y1 = y1.view(y1.shape[:3])\n",
    "        #[b*64,256,256]\n",
    "        #y2 = torch.mul(f1,y1)\n",
    "        #[b*64,256,1]\n",
    "        y2 = torch.matmul(f_div_C, y1)\n",
    "        #y3 = self.avg_pool2(y2)\n",
    "        #[b, 64, 16, 16]\n",
    "        y2 = y2.contiguous().view(b,n, int(h/self.patch_size), int(w/self.patch_size))\n",
    "        y2 = self.conv(y2)\n",
    "        #[b,64,1,1]\n",
    "        y2 = self.avg_pool1(y2)\n",
    "        return y2\n",
    "\n",
    "a = torch.randn(16,64,256,256)\n",
    "pp = PatchNonlocalPool(n_feats=64)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
